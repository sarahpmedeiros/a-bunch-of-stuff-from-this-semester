{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "from datetime import datetime\n",
    "from IPython.display import Image\n",
    "from IPython.display import display_html\n",
    "from IPython.display import display\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.sparse.linalg as linalg\n",
    "import scipy.cluster.hierarchy as hr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.utils as utils\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.cross_validation as cross_validation\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "import codecs\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "site_url = \"https://www1.eeoc.gov/\"\n",
    "base_url = \"https://www1.eeoc.gov/eeoc/statistics/employment/jobpat-eeo1\"\n",
    "\n",
    "def get_page(url):\n",
    "    response = requests.get(url)\n",
    "    html = response.text.encode('utf-8')\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_reports_page(url):\n",
    "    url = url + \"eeoc/statistics/employment/jobpat-eeo1\"\n",
    "    html = get_page(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    all_reports = soup.find('div', {'class': 'CS_Textblock_Text'}).find('ul').find_all('a')\n",
    "    for report in all_reports:\n",
    "        year = report.text.split(\" \")\n",
    "        if year[0] != \"Glossary\":\n",
    "#             if int(year[0]) == 2008:\n",
    "#                 get_industry_page('https://www.eeoc.gov/eeoc/statistics/employment/jobpat-eeo1/2008/nac2/index.html')\n",
    "#             if int(year[0]) >= 2005 and int(year[0]) <= 2007:\n",
    "#                 report_url = site_url + report['href']\n",
    "#                 parse_report_page(report_url, year[0])  \n",
    "            if int(year[0]) >= 2005 and int(year[0]) < 2007:\n",
    "                report_url = site_url + report['href']\n",
    "                parse_report_page(report_url, year[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_recent_report_page(url,year):\n",
    "    html = get_page(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')    \n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_report_page(url,year):\n",
    "    html = get_page(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')    \n",
    "    print(year)\n",
    "    print(\"here\")\n",
    "    if soup.find('h1', text=\"This Page Was Not Found.\") is None:\n",
    "        links = soup.find_all('a', text='NAICS-2 Aggregate')\n",
    "        for link in links:\n",
    "            industry_url = base_url + \"/\"+  year  +\"/\" + link['href']\n",
    "            print(industry_url)\n",
    "            get_industry_page(industry_url)\n",
    "    else:\n",
    "        print('skip')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_industry_page(url):\n",
    "    html = get_page(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    industries = soup.find('body').find('table').find_all('a',href=True)\n",
    "    stripped_url = url.split('index.html')\n",
    "    for industry in industries:\n",
    "        industry_url = stripped_url[0] + industry['href']\n",
    "        parse_industry(industry_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_industry(url):\n",
    "#     print(url)\n",
    "    html = get_page(url)\n",
    "    splitURl = (os.path.splitext(url)[0].split('/'))\n",
    "    fileName = splitURl[7] +'-'+ splitURl[8]+'-'+splitURl[9]\n",
    "    print(fileName)\n",
    "    parseHTML(html,fileName)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseHTML(x,fileName):\n",
    "#   This code parses the table that is available on EEOC website\n",
    "\n",
    "    soup = BeautifulSoup((x),'html.parser')\n",
    "    table = (soup.select('table'))[0]\n",
    "    tableHeader = table.findAll('th',{'scope':'col'})\n",
    "\n",
    "    headerRow = []\n",
    "    for x in tableHeader:\n",
    "        headerRow.append(x.text)\n",
    "    \n",
    "    body = (table.select('tbody'))\n",
    "    temp=[]\n",
    "    rows = []\n",
    "    for h in body:\n",
    "        row = (h.findAll('tr'))\n",
    "        for r in row:\n",
    "            temp.append((r.find('th').text))\n",
    "            values = (r.select('td'))\n",
    "            for v in values:\n",
    "                temp.append(v.text)\n",
    "            rows.append(temp)\n",
    "            temp=[]\n",
    "\n",
    "    with open(fileName, 'w') as f:\n",
    "        writer = csv.writer(f,delimiter=',')\n",
    "        writer.writerow([headerRow[0],headerRow[1],headerRow[2],headerRow[3],headerRow[4],headerRow[5],headerRow[6],headerRow[7],headerRow[8],headerRow[9],headerRow[10]])\n",
    "        for x in rows:\n",
    "            if (len(x)==11):\n",
    "                writer.writerow([x[0], x[1], x[2], x[3], x[4], x[5], x[6], x[7], x[8], x[9],x[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "here\n",
      "https://www1.eeoc.gov/eeoc/statistics/employment/jobpat-eeo1/2006/nac2/index.html\n",
      "2006-nac2-11\n",
      "2006-nac2-21\n",
      "2006-nac2-22\n",
      "2006-nac2-23\n",
      "2006-nac2-31\n",
      "2006-nac2-32\n",
      "2006-nac2-33\n",
      "2006-nac2-42\n",
      "2006-nac2-44\n",
      "2006-nac2-45\n",
      "2006-nac2-48\n",
      "2006-nac2-49\n",
      "2006-nac2-51\n",
      "2006-nac2-52\n",
      "2006-nac2-53\n",
      "2006-nac2-54\n",
      "2006-nac2-55\n",
      "2006-nac2-56\n",
      "2006-nac2-61\n",
      "2006-nac2-62\n",
      "2006-nac2-71\n",
      "2006-nac2-72\n",
      "2006-nac2-81\n",
      "2006-nac2-92\n",
      "2005\n",
      "here\n",
      "https://www1.eeoc.gov/eeoc/statistics/employment/jobpat-eeo1/2005/nac2/index.html\n",
      "2005-nac2-11\n",
      "2005-nac2-21\n",
      "2005-nac2-22\n",
      "2005-nac2-23\n",
      "2005-nac2-31\n",
      "2005-nac2-32\n",
      "2005-nac2-33\n",
      "2005-nac2-42\n",
      "2005-nac2-44\n",
      "2005-nac2-45\n",
      "2005-nac2-48\n",
      "2005-nac2-49\n",
      "2005-nac2-51\n",
      "2005-nac2-52\n",
      "2005-nac2-53\n",
      "2005-nac2-54\n",
      "2005-nac2-55\n",
      "2005-nac2-56\n",
      "2005-nac2-61\n",
      "2005-nac2-62\n",
      "2005-nac2-71\n",
      "2005-nac2-72\n",
      "2005-nac2-81\n",
      "2005-nac2-92\n"
     ]
    }
   ],
   "source": [
    "get_reports_page(site_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005 national agg scraped from web.csv\n",
      "here\n",
      "./2005-Data/2005 national agg scraped from web.csv\n",
      "2005 national agg.csv\n",
      "here\n",
      "./2005-Data/2005 national agg.csv\n",
      "2005-nac2\n",
      "here\n",
      "./2005-Data/2005-nac2\n",
      "2005-nac2-11\n",
      "here\n",
      "./2005-Data/2005-nac2-11\n",
      "2005-nac2-21\n",
      "here\n",
      "./2005-Data/2005-nac2-21\n",
      "2005-nac2-22\n",
      "here\n",
      "./2005-Data/2005-nac2-22\n",
      "2005-nac2-23\n",
      "here\n",
      "./2005-Data/2005-nac2-23\n",
      "2005-nac2-31\n",
      "here\n",
      "./2005-Data/2005-nac2-31\n",
      "2005-nac2-32\n",
      "here\n",
      "./2005-Data/2005-nac2-32\n",
      "2005-nac2-33\n",
      "here\n",
      "./2005-Data/2005-nac2-33\n",
      "2005-nac2-42\n",
      "here\n",
      "./2005-Data/2005-nac2-42\n",
      "2005-nac2-44\n",
      "here\n",
      "./2005-Data/2005-nac2-44\n",
      "2005-nac2-45\n",
      "here\n",
      "./2005-Data/2005-nac2-45\n",
      "2005-nac2-48\n",
      "here\n",
      "./2005-Data/2005-nac2-48\n",
      "2005-nac2-49\n",
      "here\n",
      "./2005-Data/2005-nac2-49\n",
      "2005-nac2-51\n",
      "here\n",
      "./2005-Data/2005-nac2-51\n",
      "2005-nac2-52\n",
      "here\n",
      "./2005-Data/2005-nac2-52\n",
      "2005-nac2-53\n",
      "here\n",
      "./2005-Data/2005-nac2-53\n",
      "2005-nac2-54\n",
      "here\n",
      "./2005-Data/2005-nac2-54\n",
      "2005-nac2-55\n",
      "here\n",
      "./2005-Data/2005-nac2-55\n",
      "2005-nac2-56\n",
      "here\n",
      "./2005-Data/2005-nac2-56\n",
      "2005-nac2-61\n",
      "here\n",
      "./2005-Data/2005-nac2-61\n",
      "2005-nac2-62\n",
      "here\n",
      "./2005-Data/2005-nac2-62\n",
      "2005-nac2-71\n",
      "here\n",
      "./2005-Data/2005-nac2-71\n",
      "2005-nac2-72\n",
      "here\n",
      "./2005-Data/2005-nac2-72\n",
      "2005-nac2-81\n",
      "here\n",
      "./2005-Data/2005-nac2-81\n",
      "2005-nac2-92\n",
      "here\n",
      "./2005-Data/2005-nac2-92\n",
      "2006 national agg.csv\n",
      "here\n",
      "./2006-Data/2006 national agg.csv\n",
      "2006 national agg.htm\n",
      "here\n",
      "./2006-Data/2006 national agg.htm\n"
     ]
    },
    {
     "ename": "CParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCParserError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6a15997c1638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#             print (d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#         year = (subdir.split('-')[0][2:])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mparseCSVfromWeb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-6a15997c1638>\u001b[0m in \u001b[0;36mparseCSVfromWeb\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrootdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     \u001b[0mgetDFfromMyCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#         for d in subdzr:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#             print (d)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-876a44c7ee89>\u001b[0m in \u001b[0;36mgetDFfromMyCSV\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'here'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     print (df.drop(df.index[[22,23,24,25,26,27,28]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_csv\u001b[0;34m(cls, path, header, sep, index_col, parse_dates, encoding, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[1;32m   1187\u001b[0m                           \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                           \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtupleize_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m                           infer_datetime_format=infer_datetime_format)\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m _parser_defaults = {\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_footer not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:8748)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:9003)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas/parser.c:9731)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._tokenize_rows (pandas/parser.c:9602)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.raise_parser_error (pandas/parser.c:23325)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 3\n"
     ]
    }
   ],
   "source": [
    "def parseCSVfromWeb():\n",
    "    rootdir = './'\n",
    "    folders=[]\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for d in dirs:\n",
    "            if (d[0]=='2'):\n",
    "                folders.append(d)\n",
    "#         for f in files:\n",
    "#             print (f)\n",
    "#     print (folders)\n",
    "    \n",
    "    for f in folders:\n",
    "        rootdir = './'+ f\n",
    "#         print (rootdir)\n",
    "        for subdir, dirs, files in os.walk(rootdir):\n",
    "            for file in files:\n",
    "                if (file[:2]=='20'):\n",
    "                    print (file)\n",
    "                    f = rootdir + '/' +file\n",
    "                    getDFfromMyCSV(f)\n",
    "        #         for d in subdzr:\n",
    "#             print (d)\n",
    "#         year = (subdir.split('-')[0][2:])\n",
    "parseCSVfromWeb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDFfromMyCSV(fileName):\n",
    "#   this code creates a data frame from the CSV that we created \n",
    "\n",
    "    print ('here')\n",
    "    print (fileName)\n",
    "    df = pd.DataFrame.from_csv(fileName)\n",
    "    return (df)\n",
    "#     print (df.drop(df.index[[22,23,24,25,26,27,28]]))\n",
    "# getDFfromCSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getDFfromGOVCSV(csv_input, file):\n",
    "#   this code creates a data frame from the CSV file that the government provides\n",
    "\n",
    "    index = ['ALL EMPLOYEES','Men','Women','WHITE','White Men','White Women','MINORITY',\n",
    "             'Minority Men','Minority Women','BLACK','Black Men','Black Women','HISPANIC','Hispanic Men','Hispanic Women',\n",
    "             'ASIAN AMERICAN','Asian Men', 'Asian Women','AMERICAN INDIAN','American-Indian Men','American-Indian Women',\n",
    "             'HAWAIIAN','Hawaiian Men','Hawaiian Women','TWO OR MORE RACES','Multiracial Men','Multiracial Women']\n",
    "    column = ['Total Employment','Officials & Managers','Professionals','Technicians',\n",
    "              \"Sales Workers\",'Office & Clerical Workers','Craft Workers','Operatives',\n",
    "              'Laborers','Service Workers']\n",
    "#     myDF = myDF.fillna(0)\n",
    "\n",
    "    if file:\n",
    "        dfFromFile = pd.DataFrame.from_csv(csv_input,sep=';')\n",
    "    else:\n",
    "        dfFromFile = csv_input\n",
    "            \n",
    "    sAndRace = ['TOTAL','MT','FT','WHT','WHM','WHF','MinT','MinM','MinF','BLKT','BLKM','BLKF','HISPT',\n",
    "                      'HISPM','HISPF','ASIANT','ASIANM','ASIANF','AIANT','AIANM','AIANF',\n",
    "                      'nhopiT','NHOPIM','NHOPIF','tomrT','TOMRM','TOMRF']\n",
    "    table = []\n",
    "    for x in sAndRace:\n",
    "        tempRow = []\n",
    "        for y in range(1,11):\n",
    "            if (y==1):\n",
    "                tempRow.append(dfFromFile.get_value(index='UNITED STATES',col=(x +'1')))\n",
    "            elif (y==2):\n",
    "                tempRow.append(dfFromFile.get_value(index='UNITED STATES',col=(x+'1_2')))\n",
    "            elif (y==10):\n",
    "                tempRow.insert(0,dfFromFile.get_value(index='UNITED STATES',col=(x+'10')))\n",
    "            else:\n",
    "                tempRow.append(dfFromFile.get_value(index='UNITED STATES',col=(x+str(y))))\n",
    "#             print (tempRow)\n",
    "        table.append(tempRow)\n",
    "    \n",
    "\n",
    "    myDF = pd.DataFrame(data=table, index=index, columns=column)\n",
    "    if not file:\n",
    "        print(dfFromFile['NAC2_Label'][0])\n",
    "    \n",
    "    return(myDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def linear_regression(xDF, yDF):\n",
    "    \n",
    "    X, y = utils.shuffle(xDF, yDF, random_state=1)\n",
    "    X_train, X, y_train, y = cross_validation.train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "    print((X_train.shape), y_train.shape)\n",
    "    print((X.shape), y.shape)\n",
    "    \n",
    "        \n",
    "#    fig, axes = plt.subplots(2,2,figsize=(15,10))\n",
    "\n",
    "    for i in range(4):\n",
    "#         plt_i = i // 2\n",
    "#         plt_j = i % 2\n",
    "        \n",
    "\n",
    "        subX_train = X_train[X_train.columns[i]]\n",
    "    \n",
    "        \n",
    "        le = preprocessing.LabelEncoder()\n",
    "        subX_train = le.fit_transform(subX_train)\n",
    "        \n",
    "        X_train[X_train.columns[i]]= subX_train\n",
    "\n",
    "#         axes[plt_i][plt_j].scatter(subX_train, y_train, c=\"slategray\", alpha=0.4, linewidths=0.3)\n",
    "#         axes[plt_i][plt_j].set_xlabel(X_train.columns[i])\n",
    "#         axes[plt_i][plt_j].set_ylabel('Average'); \n",
    "        \n",
    "\n",
    "    model = sm.OLS(y_train, X_train)\n",
    "    results = model.fit()\n",
    "    print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'YEAR07_US.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8f7e93f7785d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# dfList.append(df06)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf07\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDFfromGOVCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'YEAR07_US.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdfList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf07\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ab773efe6b3e>\u001b[0m in \u001b[0;36mgetDFfromGOVCSV\u001b[0;34m(csv_input, file)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdfFromFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mdfFromFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_csv\u001b[0;34m(cls, path, header, sep, index_col, parse_dates, encoding, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[1;32m   1187\u001b[0m                           \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m                           \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtupleize_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m                           infer_datetime_format=infer_datetime_format)\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'block'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Sarah/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'YEAR07_US.txt' does not exist"
     ]
    }
   ],
   "source": [
    "#gets dataframes from csv files and puts them in a list and accesses each job type(Sarah's files) - still need to do NAC classifications\n",
    "#COMPLETE DF\n",
    "dfList = []\n",
    "# df05 = getDFfromMyCSV('2005 National agg.csv')\n",
    "# dfList.append(df05) \n",
    "\n",
    "# df06 = getDFfromMyCSV('2006 National agg.csv')\n",
    "# dfList.append(df06) \n",
    "\n",
    "df07 = getDFfromGOVCSV('YEAR07_US.txt',True)\n",
    "dfList.append(df07) \n",
    "\n",
    "df08 = getDFfromGOVCSV('YEAR08_US.txt',True)\n",
    "dfList.append(df08)\n",
    "\n",
    "df09 = getDFfromGOVCSV('YEAR09_US.txt',True)\n",
    "dfList.append(df09)\n",
    "\n",
    "df10 = getDFfromGOVCSV('YEAR10_US.txt',True)\n",
    "dfList.append(df10)\n",
    "\n",
    "df11 = getDFfromGOVCSV('year11_us.txt',True)\n",
    "dfList.append(df11)\n",
    "\n",
    "df12 = getDFfromGOVCSV('year12_us.txt',True)\n",
    "dfList.append(df12)\n",
    "\n",
    "df13 = getDFfromGOVCSV('year13_us.txt',True)\n",
    "dfList.append(df13)\n",
    "\n",
    "df14 = getDFfromGOVCSV('year14_us.txt',True)\n",
    "dfList.append(df14)\n",
    "\n",
    "df15 = getDFfromGOVCSV('year15_us.txt',True)\n",
    "dfList.append(df15)\n",
    "\n",
    "\n",
    "graphGenderRace = ['White Men','White Women','Minority Men','Minority Women',\n",
    "          'Black Men','Black Women','Hispanic Men','Hispanic Women',\n",
    "          'Asian Men', 'Asian Women','American-Indian Men','American-Indian Women',\n",
    "          'Hawaiian Men','Hawaiian Women','Multiracial Men','Multiracial Women']\n",
    "\n",
    "columnX = ['Race', 'Gender','Year', 'JobType', 'Workers']   \n",
    "\n",
    "jobTypes = ['Officials & Managers', 'Professionals','Technicians', 'Sales Workers', 'Office & Clerical Workers',\n",
    "'Craft Workers','Operatives','Laborers', 'Service Workers']\n",
    "\n",
    "OfficialsManagers = [] \n",
    "Professionals = [] \n",
    "Technicians = []\n",
    "SalesWorkers = []\n",
    "OfficeClericalWorkers = []\n",
    "CraftWorkers = []\n",
    "Operatives = []\n",
    "Laborers = [] \n",
    "ServiceWorkers = []\n",
    "\n",
    "year = 2007 #TODO not sure if year goes up or down\n",
    "for df in dfList:\n",
    "    for jobType in jobTypes:\n",
    "        for demographic in graphGenderRace:\n",
    "\n",
    "            raceGender = demographic.split()\n",
    "            \n",
    "            if jobType == 'Officials & Managers':\n",
    "                tempX = OfficialsManagers\n",
    "            if jobType == 'Professionals':\n",
    "                tempX = Professionals\n",
    "            if jobType == 'Technicians':\n",
    "                tempX = Technicians\n",
    "            if jobType == 'Sales Workers':\n",
    "                tempX = SalesWorkers\n",
    "            if jobType == 'Office & Clerical Workers':\n",
    "                tempX = OfficeClericalWorkers\n",
    "            if jobType == 'Craft Workers':\n",
    "                tempX = CraftWorkers\n",
    "            if jobType == 'Operatives':\n",
    "                tempX = Operatives\n",
    "            if jobType == 'Laborers':\n",
    "                tempX = Laborers\n",
    "            if jobType == 'Service Workers':\n",
    "                tempX = ServiceWorkers\n",
    "                \n",
    "            tempX.append([raceGender[0],raceGender[1],year,jobType,df[jobType][demographic]])\n",
    "\n",
    "    year += 1\n",
    "\n",
    "OfficialsManagersDF = pd.DataFrame(data=OfficialsManagers, columns=columnX)\n",
    "ProfessionalsDF = pd.DataFrame(data=Professionals, columns=columnX)\n",
    "TechniciansDF = pd.DataFrame(data=Technicians, columns=columnX)\n",
    "SalesWorkersDF = pd.DataFrame(data=SalesWorkers, columns=columnX)\n",
    "OfficeClericalWorkersDF = pd.DataFrame(data=OfficeClericalWorkers, columns=columnX)\n",
    "CraftWorkersDF = pd.DataFrame(data=CraftWorkers, columns=columnX)\n",
    "OperativesDF = pd.DataFrame(data=Operatives, columns=columnX)\n",
    "LaborersDF = pd.DataFrame(data=Laborers, columns=columnX)\n",
    "ServiceWorkersDF = pd.DataFrame(data=ServiceWorkers, columns=columnX)\n",
    "allData = OfficialsManagers + Professionals + Technicians + SalesWorkers + OfficeClericalWorkers + CraftWorkers + Operatives + Laborers + ServiceWorkers\n",
    "\n",
    "\n",
    "allWorkers = pd.DataFrame(data=allData, columns=columnX)\n",
    "\n",
    "print(allWorkers)\n",
    "print(allWorkersY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Race Gender  Year               JobType\n",
      "0               White    Men  2007  Officials & Managers\n",
      "1               White  Women  2007  Officials & Managers\n",
      "2            Minority    Men  2007  Officials & Managers\n",
      "3            Minority  Women  2007  Officials & Managers\n",
      "4               Black    Men  2007  Officials & Managers\n",
      "5               Black  Women  2007  Officials & Managers\n",
      "6            Hispanic    Men  2007  Officials & Managers\n",
      "7            Hispanic  Women  2007  Officials & Managers\n",
      "8               Asian    Men  2007  Officials & Managers\n",
      "9               Asian  Women  2007  Officials & Managers\n",
      "10    American-Indian    Men  2007  Officials & Managers\n",
      "11    American-Indian  Women  2007  Officials & Managers\n",
      "12           Hawaiian    Men  2007  Officials & Managers\n",
      "13           Hawaiian  Women  2007  Officials & Managers\n",
      "14        Multiracial    Men  2007  Officials & Managers\n",
      "15        Multiracial  Women  2007  Officials & Managers\n",
      "16              White    Men  2008  Officials & Managers\n",
      "17              White  Women  2008  Officials & Managers\n",
      "18           Minority    Men  2008  Officials & Managers\n",
      "19           Minority  Women  2008  Officials & Managers\n",
      "20              Black    Men  2008  Officials & Managers\n",
      "21              Black  Women  2008  Officials & Managers\n",
      "22           Hispanic    Men  2008  Officials & Managers\n",
      "23           Hispanic  Women  2008  Officials & Managers\n",
      "24              Asian    Men  2008  Officials & Managers\n",
      "25              Asian  Women  2008  Officials & Managers\n",
      "26    American-Indian    Men  2008  Officials & Managers\n",
      "27    American-Indian  Women  2008  Officials & Managers\n",
      "28           Hawaiian    Men  2008  Officials & Managers\n",
      "29           Hawaiian  Women  2008  Officials & Managers\n",
      "...               ...    ...   ...                   ...\n",
      "1266         Minority    Men  2014       Service Workers\n",
      "1267         Minority  Women  2014       Service Workers\n",
      "1268            Black    Men  2014       Service Workers\n",
      "1269            Black  Women  2014       Service Workers\n",
      "1270         Hispanic    Men  2014       Service Workers\n",
      "1271         Hispanic  Women  2014       Service Workers\n",
      "1272            Asian    Men  2014       Service Workers\n",
      "1273            Asian  Women  2014       Service Workers\n",
      "1274  American-Indian    Men  2014       Service Workers\n",
      "1275  American-Indian  Women  2014       Service Workers\n",
      "1276         Hawaiian    Men  2014       Service Workers\n",
      "1277         Hawaiian  Women  2014       Service Workers\n",
      "1278      Multiracial    Men  2014       Service Workers\n",
      "1279      Multiracial  Women  2014       Service Workers\n",
      "1280            White    Men  2015       Service Workers\n",
      "1281            White  Women  2015       Service Workers\n",
      "1282         Minority    Men  2015       Service Workers\n",
      "1283         Minority  Women  2015       Service Workers\n",
      "1284            Black    Men  2015       Service Workers\n",
      "1285            Black  Women  2015       Service Workers\n",
      "1286         Hispanic    Men  2015       Service Workers\n",
      "1287         Hispanic  Women  2015       Service Workers\n",
      "1288            Asian    Men  2015       Service Workers\n",
      "1289            Asian  Women  2015       Service Workers\n",
      "1290  American-Indian    Men  2015       Service Workers\n",
      "1291  American-Indian  Women  2015       Service Workers\n",
      "1292         Hawaiian    Men  2015       Service Workers\n",
      "1293         Hawaiian  Women  2015       Service Workers\n",
      "1294      Multiracial    Men  2015       Service Workers\n",
      "1295      Multiracial  Women  2015       Service Workers\n",
      "\n",
      "[1296 rows x 4 columns]\n",
      "      Workers\n",
      "0      570228\n",
      "1      217879\n",
      "2       73414\n",
      "3       39963\n",
      "4       17045\n",
      "5       15101\n",
      "6       27358\n",
      "7       12844\n",
      "8       24071\n",
      "9        9297\n",
      "10       1965\n",
      "11       1039\n",
      "12       1284\n",
      "13        799\n",
      "14       1691\n",
      "15        883\n",
      "16     553571\n",
      "17     214164\n",
      "18      66207\n",
      "19      38444\n",
      "20      14608\n",
      "21      15019\n",
      "22      22044\n",
      "23      10919\n",
      "24      24620\n",
      "25       9519\n",
      "26       1723\n",
      "27        968\n",
      "28       1103\n",
      "29        708\n",
      "...       ...\n",
      "1266  1738317\n",
      "1267  2389914\n",
      "1268   735305\n",
      "1269  1189030\n",
      "1270   728171\n",
      "1271   842343\n",
      "1272   156267\n",
      "1273   204355\n",
      "1274    18972\n",
      "1275    31854\n",
      "1276    21503\n",
      "1277    25847\n",
      "1278    78099\n",
      "1279    96485\n",
      "1280  1434132\n",
      "1281  2302516\n",
      "1282  1787275\n",
      "1283  2520641\n",
      "1284   759951\n",
      "1285  1250560\n",
      "1286   742360\n",
      "1287   886498\n",
      "1288   162051\n",
      "1289   214098\n",
      "1290    19678\n",
      "1291    32349\n",
      "1292    22361\n",
      "1293    28402\n",
      "1294    80874\n",
      "1295   108734\n",
      "\n",
      "[1296 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#gets dataframes from csv files and puts them in a list and accesses each job type(Sarah's files) - still need to do NAC classifications\n",
    "dfList = []\n",
    "# df05 = getDFfromMyCSV('2005 National agg.csv')\n",
    "# dfList.append(df05) \n",
    "\n",
    "# df06 = getDFfromMyCSV('2006 National agg.csv')\n",
    "# dfList.append(df06) \n",
    "\n",
    "df07 = getDFfromGOVCSV('YEAR07_US.txt',True)\n",
    "dfList.append(df07) \n",
    "\n",
    "df08 = getDFfromGOVCSV('YEAR08_US.txt',True)\n",
    "dfList.append(df08)\n",
    "\n",
    "df09 = getDFfromGOVCSV('YEAR09_US.txt',True)\n",
    "dfList.append(df09)\n",
    "\n",
    "df10 = getDFfromGOVCSV('YEAR10_US.txt',True)\n",
    "dfList.append(df10)\n",
    "\n",
    "df11 = getDFfromGOVCSV('year11_us.txt',True)\n",
    "dfList.append(df11)\n",
    "\n",
    "df12 = getDFfromGOVCSV('year12_us.txt',True)\n",
    "dfList.append(df12)\n",
    "\n",
    "df13 = getDFfromGOVCSV('year13_us.txt',True)\n",
    "dfList.append(df13)\n",
    "\n",
    "df14 = getDFfromGOVCSV('year14_us.txt',True)\n",
    "dfList.append(df14)\n",
    "\n",
    "df15 = getDFfromGOVCSV('year15_us.txt',True)\n",
    "dfList.append(df15)\n",
    "\n",
    "\n",
    "graphGenderRace = ['White Men','White Women','Minority Men','Minority Women',\n",
    "          'Black Men','Black Women','Hispanic Men','Hispanic Women',\n",
    "          'Asian Men', 'Asian Women','American-Indian Men','American-Indian Women',\n",
    "          'Hawaiian Men','Hawaiian Women','Multiracial Men','Multiracial Women']\n",
    "\n",
    "columnX = ['Race', 'Gender','Year', 'JobType']   \n",
    "columnY = ['Workers']\n",
    "\n",
    "jobTypes = ['Officials & Managers', 'Professionals','Technicians', 'Sales Workers', 'Office & Clerical Workers',\n",
    "'Craft Workers','Operatives','Laborers', 'Service Workers']\n",
    "\n",
    "OfficialsManagers = [] \n",
    "Professionals = [] \n",
    "Technicians = []\n",
    "SalesWorkers = []\n",
    "OfficeClericalWorkers = []\n",
    "CraftWorkers = []\n",
    "Operatives = []\n",
    "Laborers = [] \n",
    "ServiceWorkers = []\n",
    "\n",
    "OfficialsManagersY = [] \n",
    "ProfessionalsY = [] \n",
    "TechniciansY = []\n",
    "SalesWorkersY= []\n",
    "OfficeClericalWorkersY = []\n",
    "CraftWorkersY = []\n",
    "OperativesY = []\n",
    "LaborersY = [] \n",
    "ServiceWorkersY = []\n",
    "\n",
    "year = 2007 #TODO not sure if year goes up or down\n",
    "for df in dfList:\n",
    "    for jobType in jobTypes:\n",
    "        for demographic in graphGenderRace:\n",
    "\n",
    "            raceGender = demographic.split()\n",
    "            \n",
    "            \n",
    "            if jobType == 'Officials & Managers':\n",
    "                tempX = OfficialsManagers\n",
    "                tempY =OfficialsManagersY\n",
    "            if jobType == 'Professionals':\n",
    "                tempX = Professionals\n",
    "                tempY =ProfessionalsY\n",
    "            if jobType == 'Technicians':\n",
    "                tempX = Technicians\n",
    "                tempY =TechniciansY\n",
    "            if jobType == 'Sales Workers':\n",
    "                tempX = SalesWorkers\n",
    "                tempY = SalesWorkersY\n",
    "            if jobType == 'Office & Clerical Workers':\n",
    "                tempX = OfficeClericalWorkers\n",
    "                tempY = OfficeClericalWorkersY\n",
    "            if jobType == 'Craft Workers':\n",
    "                tempX = CraftWorkers\n",
    "                tempY = CraftWorkersY\n",
    "            if jobType == 'Operatives':\n",
    "                tempX = Operatives\n",
    "                tempY = OperativesY\n",
    "            if jobType == 'Laborers':\n",
    "                tempX = Laborers\n",
    "                tempY = LaborersY\n",
    "            if jobType == 'Service Workers':\n",
    "                tempX = ServiceWorkers\n",
    "                tempY = ServiceWorkersY\n",
    "                \n",
    "            tempX.append([raceGender[0],raceGender[1],year,jobType])\n",
    "            tempY.append([df[jobType][demographic]])\n",
    "\n",
    "    year += 1\n",
    "\n",
    "OfficialsManagersDF = pd.DataFrame(data=OfficialsManagers, columns=columnX)\n",
    "OfficialsManagersDFY = pd.DataFrame(data=OfficialsManagersY, columns=columnY)\n",
    "\n",
    "ProfessionalsDF = pd.DataFrame(data=Professionals, columns=columnX)\n",
    "ProfessionalsDFY = pd.DataFrame(data=ProfessionalsY, columns=columnY)\n",
    "\n",
    "TechniciansDF = pd.DataFrame(data=Technicians, columns=columnX)\n",
    "TechniciansDFY = pd.DataFrame(data=TechniciansY, columns=columnY)\n",
    "\n",
    "SalesWorkersDF = pd.DataFrame(data=SalesWorkers, columns=columnX)\n",
    "SalesWorkersDFY = pd.DataFrame(data=SalesWorkersY, columns=columnY)\n",
    "\n",
    "OfficeClericalWorkersDF = pd.DataFrame(data=OfficeClericalWorkers, columns=columnX)\n",
    "OfficeClericalWorkersDFY = pd.DataFrame(data=OfficeClericalWorkersY, columns=columnY)\n",
    "\n",
    "CraftWorkersDF = pd.DataFrame(data=CraftWorkers, columns=columnX)\n",
    "CraftWorkersDFY = pd.DataFrame(data=CraftWorkersY, columns=columnY)\n",
    "\n",
    "OperativesDF = pd.DataFrame(data=Operatives, columns=columnX)\n",
    "OperativesDFY = pd.DataFrame(data=OperativesY, columns=columnY)\n",
    "\n",
    "LaborersDF = pd.DataFrame(data=Laborers, columns=columnX)\n",
    "LaborersDFY = pd.DataFrame(data=LaborersY, columns=columnY)\n",
    "\n",
    "ServiceWorkersDF = pd.DataFrame(data=ServiceWorkers, columns=columnX)\n",
    "ServiceWorkersDFY = pd.DataFrame(data=ServiceWorkersY, columns=columnY)\n",
    "\n",
    "allData = OfficialsManagers + Professionals + Technicians + SalesWorkers + OfficeClericalWorkers + CraftWorkers + Operatives + Laborers + ServiceWorkers\n",
    "allDataY = OfficialsManagersY + ProfessionalsY + TechniciansY + SalesWorkersY + OfficeClericalWorkersY + CraftWorkersY + OperativesY + LaborersY + ServiceWorkersY\n",
    "\n",
    "\n",
    "allWorkers = pd.DataFrame(data=allData, columns=columnX)\n",
    "allWorkersY = pd.DataFrame(data=allDataY, columns=columnY)\n",
    "\n",
    "print(allWorkers)\n",
    "print(allWorkersY)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# linear_regression(allWorkers, allWorkersY)\n",
    "\n",
    "# print(\"Technical ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "# print()\n",
    "# linear_regression(TechniciansDF, TechniciansDFY)\n",
    "\n",
    "# print(\"Clerical Workers ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "# print()\n",
    "# linear_regression(OfficeClericalWorkersDF, OfficeClericalWorkersDFY)\n",
    "\n",
    "# print(\"Laborers ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "# print()\n",
    "# linear_regression(LaborersDF, LaborersDFY)\n",
    "\n",
    "# print(\"Professional +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "# print()\n",
    "# linear_regression(ProfessionalsDF, ProfessionalsDFY)\n",
    "\n",
    "# print(\"Manager +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "# print()\n",
    "# linear_regression(OfficialsManagersDF, OfficialsManagersDFY)\n",
    "\n",
    "# print(\"Service +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "# print()\n",
    "# linear_regression(ServiceWorkersDF, ServiceWorkersDFY)\n",
    "\n",
    "# print(\"Sales +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "# print()\n",
    "# linear_regression(SalesWorkersDF, SalesWorkersDFY)\n",
    "\n",
    "# print(\"Craft +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "# print()\n",
    "# linear_regression(CraftWorkersDF, CraftWorkersDFY)\n",
    "\n",
    "# print(\"Operative +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "# print()\n",
    "# linear_regression(OperativesDF, OperativesDFY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_NAC_DFfromGOVCSV(fileName):\n",
    "    dfFromFile = pd.DataFrame.from_csv(fileName,sep=';')\n",
    "\n",
    "    keys = list(dfFromFile.keys())\n",
    "    \n",
    "    for row in dfFromFile.itertuples():\n",
    "        newDF = pd.DataFrame(data=[row[1:]],index=['UNITED STATES'], columns=keys)        \n",
    "        getDFfromGOVCSV(newDF, False)\n",
    "\n",
    "# get_NAC_DFfromGOVCSV('year15_nac2.txt')\n",
    "# get_NAC_DFfromGOVCSV('year14_nac2.txt')\n",
    "# get_NAC_DFfromGOVCSV('year13_nac2.txt')\n",
    "# get_NAC_DFfromGOVCSV('year12_nac2.txt')\n",
    "# get_NAC_DFfromGOVCSV('year11_nac2.txt')\n",
    "# get_NAC_DFfromGOVCSV('year10_nac2.txt')\n",
    "#get_NAC_DFfromGOVCSV('year09_nac2.txt')\n",
    "#get_NAC_DFfromGOVCSV('year08_nac2.txt')\n",
    "#get_NAC_DFfromGOVCSV('year07_nac2.txt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
